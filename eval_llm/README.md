Clone the [lm-evaluation-harness GitHub repository](https://github.com/EleutherAI/lm-evaluation-harness/tree/main) into this folder to perform general LLM benchmark testing.

`git clone https://github.com/EleutherAI/lm-evaluation-harness.git`

Modify and run `sh eval-LLM.sh` to run evaluation on general LLM benchmarks
